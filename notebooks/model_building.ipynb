{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4\n",
        "- Model Selection and Training\n",
        "- Model Evaluation"
      ],
      "metadata": {
        "id": "8GAKBzhxkKDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AZO4x4l2Vwro"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import joblib\n",
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install joblib\n",
        "# !pip install fastapi uvicorn pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vbQyTFhgiaeW",
        "outputId": "0d563c83-4161-4415-9971-4ca89c52e5fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.38.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.39.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_data = pd.read_csv('model_dataset.csv')\n",
        "model_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bngE1b-BWeXD",
        "outputId": "5a36322d-e049-43f2-f848-794f0e4a2165"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 95662 entries, 0 to 95661\n",
            "Data columns (total 50 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   TransactionId                95662 non-null  int64  \n",
            " 1   BatchId                      95662 non-null  int64  \n",
            " 2   AccountId                    95662 non-null  int64  \n",
            " 3   SubscriptionId               95662 non-null  int64  \n",
            " 4   CustomerId                   95662 non-null  int64  \n",
            " 5   ProviderId                   95662 non-null  int64  \n",
            " 6   ProductId                    95662 non-null  int64  \n",
            " 7   ProductCategory              95662 non-null  int64  \n",
            " 8   ChannelId                    95662 non-null  int64  \n",
            " 9   Amount                       95662 non-null  float64\n",
            " 10  Value                        95662 non-null  int64  \n",
            " 11  TransactionStartTime         95662 non-null  object \n",
            " 12  PricingStrategy              95662 non-null  int64  \n",
            " 13  FraudResult                  95662 non-null  int64  \n",
            " 14  Amount_Total                 95662 non-null  float64\n",
            " 15  Amount_Average               95662 non-null  float64\n",
            " 16  Amount_std                   95662 non-null  float64\n",
            " 17  TransactionId_frequency      95662 non-null  float64\n",
            " 18  Recency                      95662 non-null  float64\n",
            " 19  FraudResult_severity         95662 non-null  int64  \n",
            " 20  Month                        95662 non-null  int64  \n",
            " 21  Year                         95662 non-null  int64  \n",
            " 22  Day                          95662 non-null  int64  \n",
            " 23  Hour                         95662 non-null  int64  \n",
            " 24  Risk_Score                   95662 non-null  float64\n",
            " 25  Cluster                      95662 non-null  int64  \n",
            " 26  Amount_Total_woe             95662 non-null  float64\n",
            " 27  Amount_Average_woe           95662 non-null  float64\n",
            " 28  Amount_std_woe               95662 non-null  float64\n",
            " 29  TransactionId_frequency_woe  95662 non-null  float64\n",
            " 30  FraudResult_severity_woe     95662 non-null  float64\n",
            " 31  Amount_woe                   95662 non-null  float64\n",
            " 32  Value_woe                    95662 non-null  float64\n",
            " 33  Risk_Score_woe               95662 non-null  float64\n",
            " 34  TransactionId_woe            95662 non-null  float64\n",
            " 35  BatchId_woe                  95662 non-null  float64\n",
            " 36  AccountId_woe                95662 non-null  float64\n",
            " 37  SubscriptionId_woe           95662 non-null  float64\n",
            " 38  CustomerId_woe               95662 non-null  float64\n",
            " 39  ProviderId_woe               95662 non-null  float64\n",
            " 40  ProductId_woe                95662 non-null  float64\n",
            " 41  ProductCategory_woe          95662 non-null  float64\n",
            " 42  ChannelId_woe                95662 non-null  float64\n",
            " 43  PricingStrategy_woe          95662 non-null  float64\n",
            " 44  FraudResult_woe              95662 non-null  float64\n",
            " 45  Month_woe                    95662 non-null  float64\n",
            " 46  Year_woe                     95662 non-null  float64\n",
            " 47  Day_woe                      95662 non-null  float64\n",
            " 48  Hour_woe                     95662 non-null  float64\n",
            " 49  Cluster_woe                  95662 non-null  float64\n",
            "dtypes: float64(31), int64(18), object(1)\n",
            "memory usage: 36.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the previous task the important features are:\n",
        "- Amount_woe\n",
        "- Value_woe\n",
        "- Amount_Total_woe\n",
        "- TransactionId_frequency_woe\n",
        "- ProviderId_woe\n",
        "- ProductId_woe\n",
        "- ProductCategory_woe\n",
        "- ChannelId_woe\n",
        "- PricingStrategy_woe\n",
        "- Month_woe\n",
        "- Day_woe\n",
        "- Hour_woe"
      ],
      "metadata": {
        "id": "tJwWfbZGXen6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only picking important features\n",
        "df = model_data[['Amount_woe','Value_woe','Amount_Total_woe','TransactionId_frequency_woe','ProviderId_woe','ProductId_woe','ProductCategory_woe','ChannelId_woe','PricingStrategy_woe','Month_woe','Day_woe','Hour_woe','Cluster']]\n",
        "\n",
        "# training and test sets\n",
        "X = df.drop('Cluster', axis = 1)\n",
        "y = df['Cluster']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "U8qIjKVOWfQ1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Define the Random Forest classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Setup GridSearchCV with StratifiedKFold\n",
        "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=StratifiedKFold(n_splits=3), scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Train the model\n",
        "grid_search_rf.fit(x_train, y_train)\n",
        "\n",
        "# Best params and results\n",
        "print(\"Best Random Forest Params:\", grid_search_rf.best_params_)\n",
        "print(\"Random Forest Best Accuracy:\", grid_search_rf.best_score_)\n",
        "\n",
        "y_pred = grid_search_rf.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_pred_proba = grid_search_rf.predict_proba(x_test)[:, 1]  # Take probabilities for the positive class (class '1')\n",
        "\n",
        "# ROC-AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwil29GHWgeq",
        "outputId": "7a98bec1-d908-46b5-941e-13671a87ff5c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Params: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
            "Random Forest Best Accuracy: 0.9984450301517448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19069\n",
            "           1       0.92      0.75      0.83        64\n",
            "\n",
            "    accuracy                           1.00     19133\n",
            "   macro avg       0.96      0.87      0.91     19133\n",
            "weighted avg       1.00      1.00      1.00     19133\n",
            "\n",
            "ROC-AUC Score: 0.9993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create parameter grid for Gradient Boosting Machine\n",
        "param_grid_gbm = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "# Define the Gradient Boosting classifier\n",
        "gbm = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search_gbm = GridSearchCV(estimator=gbm, param_grid=param_grid_gbm, cv=StratifiedKFold(n_splits=3), scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Train the model\n",
        "grid_search_gbm.fit(x_train, y_train)\n",
        "\n",
        "# Best params and results\n",
        "print(\"Best GBM Params:\", grid_search_gbm.best_params_)\n",
        "print(\"GBM Best Accuracy:\", grid_search_gbm.best_score_)\n",
        "\n",
        "y_pred = grid_search_gbm.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_pred_proba = grid_search_gbm.predict_proba(x_test)[:, 1]  # Take probabilities for the positive class (class '1')\n",
        "\n",
        "# ROC-AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIZ046YKapmc",
        "outputId": "6832ad97-3e45-4085-e317-4bf98ccc2ffa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best GBM Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "GBM Best Accuracy: 0.9978831420861357\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19069\n",
            "           1       0.56      0.78      0.65        64\n",
            "\n",
            "    accuracy                           1.00     19133\n",
            "   macro avg       0.78      0.89      0.82     19133\n",
            "weighted avg       1.00      1.00      1.00     19133\n",
            "\n",
            "ROC-AUC Score: 0.9207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison and Insights\n",
        "\n",
        "**Overall Accuracy:**\n",
        "\n",
        "Both models show very high overall accuracy (close to 1.00), but the Random Forest slightly outperforms the GBM.\n",
        "Class Imbalance:\n",
        "\n",
        "The support for class 1 is much lower (64 instances) compared to class 0 (19069 instances), indicating a potential class imbalance issue.\n",
        "Random Forest performs better on class 1 with higher precision and recall, while GBM struggles with lower precision.\n",
        "\n",
        "**Precision and Recall:**\n",
        "\n",
        "The Random Forest has a much higher precision for class 1 (0.92) compared to GBM (0.56). This means that when Random Forest predicts a positive case (class 1), it is correct more often than the GBM.\n",
        "The recall for class 1 in both models indicates that both models capture a good proportion of actual positive cases, but the Random Forest does so more reliably.\n",
        "\n",
        "**F1-Score:**\n",
        "\n",
        "The F1-score for class 1 is significantly higher in the Random Forest model (0.83) compared to GBM (0.65), further emphasizing the Random Forest's better balance between precision and recall for this class.\n",
        "ROC-AUC Score:\n",
        "\n",
        "The Random Forest model has an excellent ROC-AUC score (0.9993), indicating it can distinguish well between the two classes. In contrast, the GBM's score (0.9207) suggests it has a harder time differentiating between the classes, likely due to the lower precision for class 1."
      ],
      "metadata": {
        "id": "PsWbmQuhjuh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the best performing model\n",
        "joblib.dump(grid_search_rf.best_estimator_, 'best_random_forest_model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKtfhA3Oiil7",
        "outputId": "24b54cfd-3bcb-4538-8858-391c579ea79c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_random_forest_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5\n",
        "- Choose a framework\n",
        "- Load the model\n",
        "- Define API endpoints\n",
        "- Handle requests\n",
        "- Return predictions\n",
        "- Deployment"
      ],
      "metadata": {
        "id": "1LvR8fT9kXHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = joblib.load('best_random_forest_model.joblib')  # Ensure this matches the uploaded filename\n",
        "\n",
        "# Create the FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "class InputData(BaseModel):\n",
        "    feature1: float\n",
        "    feature2: float\n",
        "    feature3: float\n",
        "    feature4: float\n",
        "    feature5: float\n",
        "    feature6: float\n",
        "    feature7: float\n",
        "    feature8: float\n",
        "    feature9: float\n",
        "    feature10: float\n",
        "    feature11: float\n",
        "    feature12: float\n",
        "\n",
        "@app.post('/predict')\n",
        "def predict(data: InputData):\n",
        "    input_data = [[data.feature1, data.feature2, data.feature3, data.feature4,\n",
        "                   data.feature5, data.feature6, data.feature7, data.feature8,\n",
        "                   data.feature9, data.feature10, data.feature11, data.feature12]]\n",
        "    try:\n",
        "        prediction = model.predict(input_data)\n",
        "        return {\"prediction\": prediction[0]}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n"
      ],
      "metadata": {
        "id": "1GABTEzTkpdW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uvicorn app:app --host 0.0.0.0 --port 8000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NaEJ8krkpP0",
        "outputId": "8f6adaa5-f790-48eb-80ae-e3e97f9ec6ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Could not import module \"app\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up ngro\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)  # public URL to access FastAPI app"
      ],
      "metadata": {
        "id": "N46Dw9mbko8x"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}